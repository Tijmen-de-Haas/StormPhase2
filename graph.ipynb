{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('OS_data_experiment_results.db')\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute a query on the table (replace 'experiment_results' with your table name)\n",
    "cursor.execute(\"SELECT * FROM experiment_results WHERE which_split='Test';\")\n",
    "\n",
    "# Fetch the column names\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "print(\"Column names:\", column_names)\n",
    "\n",
    "# Fetch and display rows\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(data_folder):\n",
    "    X_path = os.path.join(data_folder, \"X\")\n",
    "    y_path = os.path.join(data_folder, \"y\")\n",
    "\n",
    "    X_files = sorted(os.listdir(X_path))\n",
    "    y_files = sorted(os.listdir(y_path))\n",
    "\n",
    "    if not X_files == y_files:\n",
    "        raise RuntimeError(\"Not all training files are present in both the X and y folders.\")\n",
    "\n",
    "    file_names = X_files\n",
    "\n",
    "    X_dfs, y_dfs = [], []\n",
    "    for file in file_names:\n",
    "        X_dfs.append(pd.read_csv(os.path.join(X_path, file)))\n",
    "        y_dfs.append(pd.read_csv(os.path.join(y_path, file)))\n",
    "        \n",
    "    return X_dfs, y_dfs, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods import SingleThresholdARIMA\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.plot_functions import plot_predictions\n",
    "import jsonpickle\n",
    "import pickle\n",
    "\n",
    "home = \"/data/tijmen\"\n",
    "\n",
    "dataset = \"OS_data\" #alternatively: route_data\n",
    "data_folder = os.path.join(home, dataset)\n",
    "result_folder = os.path.join(home+\"/results\", dataset)\n",
    "intermediates_folder = os.path.join(home+ \"/intermediates\", dataset)\n",
    "model_folder = os.path.join(home + \"/saved_models\", dataset)\n",
    "\n",
    "score_folder = os.path.join(result_folder, \"scores\")\n",
    "predictions_folder = os.path.join(result_folder, \"predictions\")\n",
    "metric_folder = os.path.join(result_folder, \"metrics\")\n",
    "\n",
    "preprocessed_X_folder = os.path.join(intermediates_folder, \"preprocessed_data_csvs\")\n",
    "label_filter_folder = os.path.join(intermediates_folder, \"label_filters_per_cutoff_csvs\")\n",
    "\n",
    "test_csvs_path = '/data/tijmen/intermediates/OS_data/preprocessed_data_csvs/Test'\n",
    "preprocessing_hash ='ef19085e70a2b043dd00e10361154f3ec54122c056f0a5236099c900ff889eff'\n",
    "test_csvs_path = os.path.join(test_csvs_path, preprocessing_hash)\n",
    "X_dfs, y_dfs, dfs_files = load_batch(test_csvs_path)\n",
    "\n",
    "method = 'SingleThresholdARIMA'\n",
    "\n",
    "preds_path = os.path.join('/data/tijmen/results/OS_data/predictions/Test', preprocessing_hash, method)\n",
    "scores_path = os.path.join('/data/tijmen/results/OS_data/scores/Test', preprocessing_hash, 'ARIMA')\n",
    "\n",
    "\n",
    "best_model_entry = cursor.execute(\"\"\"\n",
    "SELECT e.* \n",
    "FROM experiment_results e \n",
    "WHERE e.metric = (\n",
    "    SELECT MAX(metric)\n",
    "    FROM experiment_results\n",
    "    WHERE method = (?) AND which_split = (?)\n",
    ") AND e.method = (?)\n",
    "\"\"\", (method, \"Test\", method))\n",
    "\n",
    "(preprocessing_hash, hyperparameter_hash, _, _, preprocessing_hyperparameter_string_pickle, hyperparameter_string_pickle, validation_metric) = next(best_model_entry)\n",
    "\n",
    "model_hyperparameters = jsonpickle.decode(hyperparameter_string_pickle, keys=True)\n",
    "model = SingleThresholdARIMA(model_folder, preprocessing_hash, **model_hyperparameters)\n",
    "\n",
    "model.load_model()\n",
    "\n",
    "preds_path = os.path.join(preds_path, hyperparameter_hash, '(3, 3, 3).pickle')\n",
    "with open(preds_path, 'rb') as handle:\n",
    "        predictions = pickle.load(handle)\n",
    "        \n",
    "scores_path = os.path.join(scores_path, hyperparameter_hash, 'scores.pickle')\n",
    "with open(scores_path, 'rb') as handle:\n",
    "        scores = pickle.load(handle)\n",
    "\n",
    "plot_predictions(X_dfs, y_dfs, predictions, dfs_files, model,  which_stations = [0,6,7], n_stations = 3, scores=scores)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods import SequentialEnsemble\n",
    "\n",
    "method = 'Sequential-DoubleThresholdBS+SingleThresholdSPC'\n",
    "\n",
    "preds_path = os.path.join('/data/tijmen/results/OS_data/predictions/Test', preprocessing_hash, method)\n",
    "scores_path = os.path.join('/data/tijmen/results/OS_data/scores/Test', preprocessing_hash, method)\n",
    "\n",
    "\n",
    "best_model_entry = cursor.execute(\"\"\"\n",
    "SELECT e.* \n",
    "FROM experiment_results e \n",
    "WHERE e.metric = (\n",
    "    SELECT MAX(metric)\n",
    "    FROM experiment_results\n",
    "    WHERE method = (?) AND which_split = (?)\n",
    ") AND e.method = (?)\n",
    "\"\"\", (method, \"Test\", method))\n",
    "\n",
    "(preprocessing_hash, hyperparameter_hash, _, _, preprocessing_hyperparameter_string_pickle, hyperparameter_string_pickle, validation_metric) = next(best_model_entry)\n",
    "\n",
    "model_hyperparameters = jsonpickle.decode(hyperparameter_string_pickle, keys=True)\n",
    "model = SequentialEnsemble(model_folder, preprocessing_hash, **model_hyperparameters)\n",
    "model.load_model()\n",
    "\n",
    "preds_path = os.path.join(preds_path, hyperparameter_hash, 'predictions.pickle')\n",
    "with open(preds_path, 'rb') as handle:\n",
    "        predictions = pickle.load(handle)\n",
    "        \n",
    "scores_path = os.path.join(scores_path, hyperparameter_hash, 'scores.pickle')\n",
    "with open(scores_path, 'rb') as handle:\n",
    "        scores = pickle.load(handle)\n",
    "\n",
    "plot_predictions(X_dfs, y_dfs, predictions, dfs_files, model,  which_stations = [0,6,7], n_stations = 3, scores=scores)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods import SequentialEnsemble\n",
    "import numpy as np\n",
    "\n",
    "method = 'Sequential-DoubleThresholdBS+SingleThresholdARIMA'\n",
    "\n",
    "preds_path = os.path.join('/data/tijmen/results/OS_data/predictions/Test', preprocessing_hash, method)\n",
    "scores_path = os.path.join('/data/tijmen/results/OS_data/scores/Test', preprocessing_hash, method)\n",
    "\n",
    "\n",
    "best_model_entry = cursor.execute(\"\"\"\n",
    "SELECT e.* \n",
    "FROM experiment_results e \n",
    "WHERE e.metric = (\n",
    "    SELECT MAX(metric)\n",
    "    FROM experiment_results\n",
    "    WHERE method = (?) AND which_split = (?)\n",
    ") AND e.method = (?)\n",
    "\"\"\", (method, \"Test\", method))\n",
    "\n",
    "(preprocessing_hash, hyperparameter_hash, _, _, preprocessing_hyperparameter_string_pickle, hyperparameter_string_pickle, validation_metric) = next(best_model_entry)\n",
    "\n",
    "model_hyperparameters = jsonpickle.decode(hyperparameter_string_pickle, keys=True)\n",
    "model = SequentialEnsemble(model_folder, preprocessing_hash, **model_hyperparameters)\n",
    "model.load_model()\n",
    "\n",
    "preds_path = os.path.join(preds_path, hyperparameter_hash, 'predictions.pickle')\n",
    "with open(preds_path, 'rb') as handle:\n",
    "        predictions = pickle.load(handle)\n",
    "        \n",
    "scores_path = os.path.join(scores_path, hyperparameter_hash, 'scores.pickle')\n",
    "with open(scores_path, 'rb') as handle:\n",
    "        scores = pickle.load(handle)\n",
    "\n",
    "plot_predictions(X_dfs, y_dfs, predictions, dfs_files, model,  which_stations = list(range(60)), scores=scores)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
